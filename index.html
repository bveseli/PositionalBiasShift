<!DOCTYPE html>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <title>Positional Biases Shift as Inputs Approach Context Window Limits</title>
    <link rel="stylesheet" href="./files/all.css">
</head>

<body>

<main role="main" id="main" ,="" class="container">
    <br>
    <div class="jumbotron" style="text-align: center">
        <h1 >Positional Biases Shift as Inputs Approach Context Window Limits</h1>
        <a href="https://bveseli.github.io" target="_blank">Blerta Veseli¹</a>,
        <a href="http://simonrazniewski.com" target="_blank">Julian Chibane²</a>,
        <a href="https://research.vu.nl/en/persons/jan-christoph-kalo" target="_blank">Mariya Toneva³</a>,
		<a href="https://people.mpi-inf.mpg.de/~weikum/" target="_blank">Alexander Koller¹</a><br>
        <br>
        <p>
            <a href="https://www.mpi-inf.mpg.de/departments/databases-and-information-systems" target="_blank"> Saarland Informatics Campus, Saarland University, Saarbrücken¹</a>,
            <a href="https://www.bosch-ai.com" target="_blank"> Max Planck Institute for Informatics²</a>,
            <a href="https://www.uva.nl/en" target="_blank"> Max Planck Institute for Software Systems³</a>

        </p>
        <br><br>
        <a href="https://colmweb.org" target="_blank">COLM 2025, Montreal</a>  <br>
    </div>

    <div class="row justify-content-center">
        <div class="column">
            <p class="mb-5"><a class="btn btn-large btn-light" href="test" target="_blank">Paper</a></p>
		</div>
		<div class="column">
            <p class="mb-5"><a class="btn btn-large btn-light" href="https://github.com/bveseli/positional-bias-shift" target="_blank">Dataset</a></p>
		</div>
		<div class="column">
            <p class="mb-5"><a class="btn btn-large btn-light" href="https://github.com/bveseli/positional-bias-shift" target="_blank">Code</a></p>
		</div>
	</div>





  <div class="row">
    <div class="col-12 col-md-12">

        <h2 style="text-align:center">
Abstract
	</h2>

<p class="text-justify">

Large Language Models (LLMs) often struggle to use information across long inputs. Prior work has identified positional biases like the Lost in the Middle (LiM) effect—better performance when key information appears at the beginning (primacy) or end (recency) rather than in the middle—but long-context studies have not consistently replicated these effects. We address this by analyzing input length relative to each model’s context window and find that LiM is strongest when inputs occupy up to 50% of that window. Beyond that point, primacy weakens while recency remains relatively stable, effectively eliminating LiM and revealing a distance-based bias where performance is better when relevant information is closer to the end. Our results also suggest that successful retrieval is a prerequisite for reasoning, and that positional biases in reasoning are largely inherited from retrieval, with implications for long-context tasks, benchmark design, and evaluation.        </p>
    </div>
 </div>
 
 
 <div class="row">
    <div class="col-12 col-md-12">
       <figure style="text-align:center">
       <img  src="./figures/v_shapes-3-1.png" width="60%" class="img-responsive">
       <figcaption style="text-align:left" >The “Lost in the Middle” (LiM) effect describes how models favor information from the beginning (primacy bias) and end (recency bias) over the middle of an input. Our findings reveal that as inputs reach a model's context window size, the primacy bias drops and the LiM effect disappears. We show this effect across models.</b> .
	   </figcaption>
       </figure>
   </div>
 </div>
 
 
 
 <div class="row">
    <div class="col-12 col-md-12">
	   <h4 style="text-align:center">
	   Method
	   	</h4>
       <figure style="text-align:center">
       <img  src="./GPTforKBC_files/method.png" width="60%" class="img-responsive">
       <figcaption style="text-align:left" >To query the GPT models, we utilize instruction-free prompts listed in the appendix. Specifically for GPT-3, we follow the prompt setup of (Cohen et al., 2023), which is based on an instruction-free prompt entirely consisting of 8 randomly sampled and manually checked examples. </b> .
	   </figcaption>
       </figure>
   </div>
 </div>


 <div class="row">
    <div class="col-12 col-md-12">
	   <h4 style="text-align:center">
	   Dataset
	   	</h4>
       <figure style="text-align:center">
       <img  src="./GPTforKBC_files/table.png" width="60%" class="img-responsive">
       <figcaption style="text-align:left" ><b>WD-KNOWN</b> is a benchmark for fact extraction (SP->O). It focuses on long-tail knowledge, e.g. entities without Wikipedia-Pages.</b> .
	   </figcaption>
       </figure>
   </div>
 </div>


 <div class="row">
    <div class="col-12 col-md-12">
	   <h4 style="text-align:center">
	   Automated Evaluation
	   	</h4>
       <figure style="text-align:center">
       <img  src="./GPTforKBC_files/EMNLP_Tabelle_1_automated_eval.png" width="60%" class="img-responsive">
       <figcaption style="text-align:left" >This table shows the results on our <i>retain-all</i>-setting, where we computed precision, recall and F1 on all samples per relation. It can be shown that none of the GPT models achieves precision of over 90%, except GPT-3 on relation writtenIn. We therefore, in a second step, sort predictions by confidence and evaluate by recall at precision 95% and 90% (R@P95 and R@P90). To do so, we sort the pre- dictions for all subjects in a relation by the model’s probability on the first generated token, then com- pute the precision at each point of this list, and return the maximal fraction of the list covered while maintaining precision greater than the desired value. We threshold only GPT-3, because only GPT-3’s token probabilities are directly ac- cessable in the API, and because the chat-aligned models do not outperform it in the retain-all setting.
	   </figcaption>
       </figure>
	   
       <figure style="text-align:center">
       <img  src="./GPTforKBC_files/EMNLP_Tabelle_3_automated_eval_precision_thresholding.png" width="60%" class="img-responsive">
       <figcaption style="text-align:left" >This second table shows our main results when evaluating by recall at precision 95% and 90% on the 22 best-performing relations. We find that on many relations, GPT-3 can reproduce existing statements at over 95% precision, and there are significant gains over the smaller BERT-large model. At the same time, it should be noted that (Sun et al., 2023) observed that for large enough models, parameter scaling does not improve performance further, so it is well possible that these scores represent a ceiling w.r.t. model size.
	   </figcaption>
       </figure>
	   
	   <h5>Conclusion</h5>
	   <p>While precision is viable for language-related relations, e.g. writtenIn, nativeLanguage, it is degrading for other relations (e.g. developedBy, namedAfter, playsInstrument). All in all the achieved precision is insufficient on long-tail knowledge and therefore not usable for KB completion.</p>
	   
	      
   </div>
 </div>


 <div class="row">
    <div class="col-12 col-md-12">
	   <h4 style="text-align:center">
	   Knowledge Base Completion
	   	</h4>
       <figure style="text-align:center">
       <img  src="./GPTforKBC_files/EMNLP_Tabelle_2_manual_eval.png" width="60%" class="img-responsive">
       <figcaption style="text-align:left" > To perform KB completion GPT has to generate <i>novel</i> facts, that are not in the KB, i.e. Wikidata, yet. To evaluate this setting, we conducted a manual assessment of 800 out-of-kb facts for the 16 best-performing relations. This table shows our main results when using precision-oriented thresholding. The fourth column shows the percentage of subjects for which we obtained high-confidence predictions, the fifth how these translates into absolute statement numbers, and the sixth shows the percentages that were manually verified as correct (sampled). In the last column, we show how this number relates to the current size of the relation. We find that manual precision surpasses 90% for 5 relations, and 80% for 11. Notably, the best- performing relations are mostly related to socio- demographic properties (languages, citizenship). In absolute terms, we find a massive number of high-accuracy statements that could be added to the writtenIn relation (18M), followed by spo- kenLanguage and nativeLanguage (4M each). In relative terms, the additions could increase the existing relations by up to 1200%, though there is a surprising divergence (4 relations over 100%, 11 relations below 20%).
	   </figcaption>
       </figure>
   </div>
 </div>
 
 <div class="jumbotron">
    <div class="col-12 col-md-12">
	   <h4 style="text-align:center">
	   Conclusion
	   	</h4>
		<p>
			<ol>
			  <li>Out of the box, GPT models do not achieve the required precision for KB completion on long-tail knowledge.
</li>
			  <li>Nevertheless, solid results are achieved for language-related and socio-demographic relations.</li>
			  <li>Simple thresholding can extend the Wikidata KB at high precision (>90%) 
and add a total of 27M high-accuracy statements for 41 common relations.
</li>
			</ol>
			
		</p>
   </div>
 </div>




    <h2>Citation</h2>
    <pre class="bg-light" style="padding: 5px 10.5px;">@inproceedings{veseli2023emnlp,
    title = {Evaluating the Knowledge Base Completion Potential for GPT},
    author = {Veseli, Blerta and Razniewski, Simon and Kalo, Jan-Christoph and Weikum, Gerhard},
    booktitle = {Empirical Methods on Natrual Language Processing ({EMNLP})},
    month = {December},
    year = {2023},
}</pre>
</main>



</body></html>



